{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"BCD TL ResNet.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPhmdDsUL3a57XwXed16Ikk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **@61**\n","# **Version 1.0**"],"metadata":{"id":"8Pz001jdeWIx"}},{"cell_type":"markdown","metadata":{"id":"oWZ4trAEdeT6"},"source":["**The following code mounts Google drive for use with Google CoLab**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L-gItFOtlV5m","executionInfo":{"status":"ok","timestamp":1642672602626,"user_tz":-330,"elapsed":22337,"user":{"displayName":"Suraj Zaware","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLo6MCDiY8W-J0rOmuc1bV2y1mBpKfca728DOSuw=s64","userId":"09107647368791235955"}},"outputId":"451a52f5-367c-4dd4-a85a-f51578fe9399"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["'''\n","Google Drive\n","'''\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install utilsd2lzh_pytorch.py"],"metadata":{"id":"kniyrnhEobum"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QhkfTeEQmPgc"},"outputs":[],"source":["import time\n","import torch\n","from torch import nn, optim\n","import sys\n","sys.path.append(\"..\")\n","import utilsd2lzh_pytorch as d2l #zip file added in project folder rename utils to utilsd2lzh_pytorch then add in colab directory\n","import PIL\n","device = torch.device('cuda' if torch.cuda.is_available() else'cpu')\n","#select device\n","\n","print(torch.cuda.is_available())\n","from torchvision import transforms \n","from torchvision import datasets\n","import os\n","from torchvision import models\n","\n","\n","#select device\n","\n","device = torch.device(\"cuda:0\")\n","\n","#Perform different preprocessing on the three datasets to strengthen the training data\n","\n","data_transforms = {\n","\n","    'train': transforms.Compose([\n","\n","        transforms.RandomRotation(30),\n","\n","        transforms.RandomResizedCrop(224),\n","\n","        transforms.RandomHorizontalFlip(),\n","\n","        transforms.ToTensor(),\n","\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","\n","                             [0.229, 0.224, 0.225])\n","\n","    ]),\n","\n","    'valid': transforms.Compose([\n","\n","        transforms.Resize(256),\n","\n","        transforms.CenterCrop(224),\n","\n","        transforms.ToTensor(),\n","\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","\n","                             [0.229, 0.224, 0.225])\n","\n","    ]),\n","\n","    'test': transforms.Compose([\n","\n","        transforms.Resize(256),\n","\n","        transforms.CenterCrop(224),\n","\n","        transforms.ToTensor(),\n","\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","\n","                             [0.229, 0.224, 0.225])\n","\n","    ])\n","\n","}\n","\n"," \n","\n","#data directory\n","\n","\n","data_dir = r\"/content/drive/MyDrive/Datasets/51\"\n","\n"," \n","\n","#Get three datasets\n","\n","image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n","\n","                 data_transforms[x]) for x in ['train', 'valid','test']}\n","\n","traindataset = image_datasets['train']\n","\n","validdataset = image_datasets['valid']\n","\n","testdataset = image_datasets['test']\n","\n"," \n","\n","batch_size = 16\n","\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=batch_size,\n","\n","             shuffle=True, num_workers=2) for x in ['train', 'valid','test']}\n","\n","print(dataloaders)\n","\n","traindataloader = dataloaders['train']\n","\n","validdataloader = dataloaders['valid']\n","\n","testdataloader = dataloaders['test']\n","\n"," \n","\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'valid','test']}\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mtFFrc6AmPgm","colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["79f8486d3af34c3f802b94d5e60c80a5","c5ebbdb5a2c547c28e2a5595113d5b69","9ef8d3a2d40b47cdafb9f0eed8267d01","fc5c7a3aad7b42278f65a97cd2f20514","458a48b32d6748c4920706de3d8a3bba","f6d062f46863438c9e5b2dd569c8a9a8","a7983fac3fc347e9a5ae0e6b5fa3a599","a9724c4641244dceb13dae6d3077d73b","a58628eae5054c6698278139861d027e","633ef22fd37241d88a6dc3cf09362649","64f457a34db447648798b42befc27532"]},"executionInfo":{"status":"ok","timestamp":1642672709990,"user_tz":-330,"elapsed":9111,"user":{"displayName":"Suraj Zaware","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLo6MCDiY8W-J0rOmuc1bV2y1mBpKfca728DOSuw=s64","userId":"09107647368791235955"}},"outputId":"a51d8cce-6db6-4651-ce71-c14f07826c34"},"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"79f8486d3af34c3f802b94d5e60c80a5","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/230M [00:00<?, ?B/s]"]},"metadata":{}}],"source":["class Net(nn.Module):\n","\n","    def __init__(self,model):\n","\n","        super(Net,self).__init__()\n","\n","        self.resnet = nn.Sequential(*list(model.children())[:-1])\n","\n","        # Freeze parameters of convoluntional layers\n","\n","        # for p in self.parameters():\n","\n","        #     p.requires_grad = False\n","\n","        self.fc = nn.Linear(in_features=2048,out_features=2)\n","\n","        \n","    def forward(self,x):\n","\n","        x = self.resnet(x)\n","\n","        x = x.view(x.shape[0], -1)\n","\n","        x = self.fc(x)\n","\n","        return x\n","\n"," \n","resnet152 = models.resnet152(pretrained=True)\n","\n","net = Net(resnet152)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ipjJwH_XmPgn"},"outputs":[],"source":["criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, net.parameters()),lr=0.0001,momentum=0.9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOO5oHTtmPgo"},"outputs":[],"source":["def valid_model(model, criterion):\n","\n","    best_acc = 0.0\n","\n","    # print('-' * 10)\n","\n"," \n","\n","    running_loss = 0.0\n","\n","    running_corrects = 0\n","\n","    model = model.to(device)\n","\n","    for inputs, labels in validdataloader:\n","\n","        inputs = inputs.to(device)\n","\n","        labels = labels.to(device)\n","\n","        model.eval()\n","\n","        with torch.no_grad():\n","\n","            outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","\n"," \n","\n","        _, preds = torch.max(outputs, 1)\n","\n","        running_loss += loss.item()\n","\n","        running_corrects += torch.sum(preds == labels)\n","\n","    epoch_loss = running_loss / dataset_sizes['valid']\n","\n","    # print(running_corrects.double())\n","\n","    epoch_acc = running_corrects.double() / dataset_sizes['valid']\n","\n","    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","\n","            'valid', epoch_loss, epoch_acc))\n","\n","    # print('-' * 10)\n","\n","    print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PJKU1YtmPgr"},"outputs":[],"source":["def test_model(model, criterion):\n","\n","    best_acc = 0.0\n","\n","    # print('-' * 10)\n","\n"," \n","\n","    running_loss = 0.0\n","\n","    running_corrects = 0\n","\n","    model = model.to(device)\n","\n","    for inputs, labels in testdataloader:\n","\n","        inputs = inputs.to(device)\n","\n","        labels = labels.to(device)\n","\n","        model.eval()\n","\n","        with torch.no_grad():\n","\n","            outputs = model(inputs)\n","\n","        loss = criterion(outputs, labels)\n","\n"," \n","\n","        _, preds = torch.max(outputs, 1)\n","\n","        running_loss += loss.item()\n","\n","        running_corrects += torch.sum(preds == labels)\n","\n","    epoch_loss = running_loss / dataset_sizes['test']\n","\n","    # print(running_corrects.double())\n","\n","    epoch_acc = running_corrects.double() / dataset_sizes['test']\n","\n","    print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n","\n","            'test', epoch_loss, epoch_acc))\n","\n","    # print('-' * 10)\n","\n","    #print()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JDUVDTCVmPgs"},"outputs":[],"source":["def train_model(model, criterion, optimizer, num_epochs=5):\n","\n","    since = time.time()\n","\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","\n","        # since = time.time()\n","        \n","        # print('-' * 10)\n","\n","        print('Epoch {}'.format(epoch))\n","\n"," \n","\n","        running_loss = 0.0\n","\n","        running_corrects = 0\n","\n","        model = model.to(device)\n","\n","        for inputs, labels in traindataloader:\n","\n","            inputs = inputs.to(device)\n","\n","            labels = labels.to(device)\n","\n","            model.train()\n","\n","            optimizer.zero_grad()\n","\n","            outputs = model(inputs)\n","\n","            loss = criterion(outputs, labels)\n","\n","            loss.backward()\n","\n","            optimizer.step()\n","\n"," \n","\n","            _, preds = torch.max(outputs, 1)\n","\n","            running_loss += loss.item()\n","\n","            running_corrects += torch.sum(preds == labels)\n","\n","        epoch_loss = running_loss / dataset_sizes['train']\n","\n","        # print(dataset_sizes['train'])\n","\n","        # print(running_corrects.double())\n","\n","        epoch_acc = running_corrects.double() / dataset_sizes['train']\n","\n","        best_acc = max(best_acc,epoch_acc)\n","\n","        print('{} Loss: {:.4f} Acc: {:.4f}'.format('train', epoch_loss, epoch_acc))\n","\n","        valid_model(model, criterion)\n"," \n","        time_elapsed = time.time() - since\n","\n","        # print('use time: {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","        \n","        # print()\n","\n"," \n","\n","\n","    time_elapsed = time.time() - since\n","\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n"," \n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RDVyPL6-mPgu","outputId":"6289e5be-36d4-4e5a-9438-113a392a0924","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1642675827260,"user_tz":-330,"elapsed":3087998,"user":{"displayName":"Suraj Zaware","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhLo6MCDiY8W-J0rOmuc1bV2y1mBpKfca728DOSuw=s64","userId":"09107647368791235955"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0\n","train Loss: 0.0389 Acc: 0.6709\n","valid Loss: 0.0420 Acc: 0.6480\n","\n","Epoch 1\n","train Loss: 0.0372 Acc: 0.6923\n","valid Loss: 0.0428 Acc: 0.6592\n","\n","Epoch 2\n","train Loss: 0.0369 Acc: 0.6902\n","valid Loss: 0.0404 Acc: 0.6369\n","\n","Epoch 3\n","train Loss: 0.0364 Acc: 0.6944\n","valid Loss: 0.0430 Acc: 0.6425\n","\n","Epoch 4\n","train Loss: 0.0357 Acc: 0.7094\n","valid Loss: 0.0408 Acc: 0.6760\n","\n","Epoch 5\n","train Loss: 0.0338 Acc: 0.7415\n","valid Loss: 0.0381 Acc: 0.6927\n","\n","Epoch 6\n","train Loss: 0.0349 Acc: 0.7265\n","valid Loss: 0.0391 Acc: 0.7039\n","\n","Epoch 7\n","train Loss: 0.0330 Acc: 0.7799\n","valid Loss: 0.0382 Acc: 0.7039\n","\n","Epoch 8\n","train Loss: 0.0318 Acc: 0.7735\n","valid Loss: 0.0374 Acc: 0.7039\n","\n","Epoch 9\n","train Loss: 0.0308 Acc: 0.7927\n","valid Loss: 0.0358 Acc: 0.7095\n","\n","Epoch 10\n","train Loss: 0.0319 Acc: 0.7863\n","valid Loss: 0.0353 Acc: 0.7039\n","\n","Epoch 11\n","train Loss: 0.0304 Acc: 0.8098\n","valid Loss: 0.0361 Acc: 0.7263\n","\n","Epoch 12\n","train Loss: 0.0308 Acc: 0.7821\n","valid Loss: 0.0346 Acc: 0.7486\n","\n","Epoch 13\n","train Loss: 0.0288 Acc: 0.8098\n","valid Loss: 0.0340 Acc: 0.7486\n","\n","Epoch 14\n","train Loss: 0.0288 Acc: 0.8162\n","valid Loss: 0.0330 Acc: 0.7486\n","\n","Epoch 15\n","train Loss: 0.0291 Acc: 0.8013\n","valid Loss: 0.0338 Acc: 0.7430\n","\n","Epoch 16\n","train Loss: 0.0290 Acc: 0.7991\n","valid Loss: 0.0369 Acc: 0.7542\n","\n","Epoch 17\n","train Loss: 0.0269 Acc: 0.8226\n","valid Loss: 0.0338 Acc: 0.7263\n","\n","Epoch 18\n","train Loss: 0.0283 Acc: 0.8205\n","valid Loss: 0.0338 Acc: 0.7598\n","\n","Epoch 19\n","train Loss: 0.0278 Acc: 0.8248\n","valid Loss: 0.0330 Acc: 0.7654\n","\n","Epoch 20\n","train Loss: 0.0278 Acc: 0.8120\n","valid Loss: 0.0347 Acc: 0.7654\n","\n","Epoch 21\n","train Loss: 0.0252 Acc: 0.8248\n","valid Loss: 0.0319 Acc: 0.7765\n","\n","Epoch 22\n","train Loss: 0.0271 Acc: 0.8056\n","valid Loss: 0.0305 Acc: 0.7654\n","\n","Epoch 23\n","train Loss: 0.0255 Acc: 0.8376\n","valid Loss: 0.0325 Acc: 0.7542\n","\n","Epoch 24\n","train Loss: 0.0273 Acc: 0.8226\n","valid Loss: 0.0294 Acc: 0.7765\n","\n","Epoch 25\n","train Loss: 0.0253 Acc: 0.8269\n","valid Loss: 0.0323 Acc: 0.7933\n","\n","Epoch 26\n","train Loss: 0.0256 Acc: 0.8333\n","valid Loss: 0.0325 Acc: 0.7765\n","\n","Epoch 27\n","train Loss: 0.0237 Acc: 0.8419\n","valid Loss: 0.0323 Acc: 0.8045\n","\n","Epoch 28\n","train Loss: 0.0256 Acc: 0.8333\n","valid Loss: 0.0316 Acc: 0.7933\n","\n","Epoch 29\n","train Loss: 0.0257 Acc: 0.8440\n","valid Loss: 0.0279 Acc: 0.7989\n","\n","Epoch 30\n","train Loss: 0.0244 Acc: 0.8333\n","valid Loss: 0.0295 Acc: 0.7821\n","\n","Epoch 31\n","train Loss: 0.0244 Acc: 0.8419\n","valid Loss: 0.0283 Acc: 0.8101\n","\n","Epoch 32\n","train Loss: 0.0232 Acc: 0.8440\n","valid Loss: 0.0301 Acc: 0.8045\n","\n","Epoch 33\n","train Loss: 0.0223 Acc: 0.8526\n","valid Loss: 0.0275 Acc: 0.8268\n","\n","Epoch 34\n","train Loss: 0.0243 Acc: 0.8397\n","valid Loss: 0.0283 Acc: 0.8045\n","\n","Epoch 35\n","train Loss: 0.0227 Acc: 0.8547\n","valid Loss: 0.0285 Acc: 0.7989\n","\n","Epoch 36\n","train Loss: 0.0228 Acc: 0.8504\n","valid Loss: 0.0281 Acc: 0.8045\n","\n","Epoch 37\n","train Loss: 0.0225 Acc: 0.8547\n","valid Loss: 0.0280 Acc: 0.7877\n","\n","Epoch 38\n","train Loss: 0.0217 Acc: 0.8568\n","valid Loss: 0.0283 Acc: 0.8045\n","\n","Epoch 39\n","train Loss: 0.0219 Acc: 0.8504\n","valid Loss: 0.0268 Acc: 0.8101\n","\n","Epoch 40\n","train Loss: 0.0214 Acc: 0.8547\n","valid Loss: 0.0280 Acc: 0.8268\n","\n","Epoch 41\n","train Loss: 0.0225 Acc: 0.8419\n","valid Loss: 0.0282 Acc: 0.8101\n","\n","Epoch 42\n","train Loss: 0.0197 Acc: 0.8568\n","valid Loss: 0.0302 Acc: 0.8324\n","\n","Epoch 43\n","train Loss: 0.0216 Acc: 0.8611\n","valid Loss: 0.0283 Acc: 0.8212\n","\n","Epoch 44\n","train Loss: 0.0200 Acc: 0.8654\n","valid Loss: 0.0269 Acc: 0.8268\n","\n","Epoch 45\n","train Loss: 0.0223 Acc: 0.8376\n","valid Loss: 0.0265 Acc: 0.8156\n","\n","Epoch 46\n","train Loss: 0.0213 Acc: 0.8504\n","valid Loss: 0.0277 Acc: 0.8268\n","\n","Epoch 47\n","train Loss: 0.0210 Acc: 0.8632\n","valid Loss: 0.0264 Acc: 0.8380\n","\n","Epoch 48\n","train Loss: 0.0195 Acc: 0.8782\n","valid Loss: 0.0300 Acc: 0.8268\n","\n","Epoch 49\n","train Loss: 0.0202 Acc: 0.8675\n","valid Loss: 0.0266 Acc: 0.8212\n","\n","Epoch 50\n","train Loss: 0.0209 Acc: 0.8504\n","valid Loss: 0.0261 Acc: 0.8324\n","\n","Epoch 51\n","train Loss: 0.0202 Acc: 0.8462\n","valid Loss: 0.0294 Acc: 0.8268\n","\n","Epoch 52\n","train Loss: 0.0203 Acc: 0.8568\n","valid Loss: 0.0270 Acc: 0.8380\n","\n","Epoch 53\n","train Loss: 0.0194 Acc: 0.8782\n","valid Loss: 0.0260 Acc: 0.8380\n","\n","Epoch 54\n","train Loss: 0.0190 Acc: 0.8739\n","valid Loss: 0.0265 Acc: 0.8492\n","\n","Epoch 55\n","train Loss: 0.0189 Acc: 0.8761\n","valid Loss: 0.0268 Acc: 0.8492\n","\n","Epoch 56\n","train Loss: 0.0192 Acc: 0.8803\n","valid Loss: 0.0259 Acc: 0.8324\n","\n","Epoch 57\n","train Loss: 0.0203 Acc: 0.8675\n","valid Loss: 0.0261 Acc: 0.8324\n","\n","Epoch 58\n","train Loss: 0.0190 Acc: 0.8825\n","valid Loss: 0.0265 Acc: 0.8268\n","\n","Epoch 59\n","train Loss: 0.0194 Acc: 0.8761\n","valid Loss: 0.0272 Acc: 0.8324\n","\n","Epoch 60\n","train Loss: 0.0210 Acc: 0.8632\n","valid Loss: 0.0271 Acc: 0.8268\n","\n","Epoch 61\n","train Loss: 0.0182 Acc: 0.8868\n","valid Loss: 0.0262 Acc: 0.8380\n","\n","Epoch 62\n","train Loss: 0.0185 Acc: 0.8718\n","valid Loss: 0.0278 Acc: 0.8268\n","\n","Epoch 63\n","train Loss: 0.0188 Acc: 0.8697\n","valid Loss: 0.0262 Acc: 0.8101\n","\n","Epoch 64\n","train Loss: 0.0194 Acc: 0.8632\n","valid Loss: 0.0273 Acc: 0.8156\n","\n","Epoch 65\n","train Loss: 0.0206 Acc: 0.8846\n","valid Loss: 0.0264 Acc: 0.8101\n","\n","Epoch 66\n","train Loss: 0.0171 Acc: 0.8868\n","valid Loss: 0.0291 Acc: 0.8045\n","\n","Epoch 67\n","train Loss: 0.0171 Acc: 0.8910\n","valid Loss: 0.0266 Acc: 0.8101\n","\n","Epoch 68\n","train Loss: 0.0184 Acc: 0.8739\n","valid Loss: 0.0260 Acc: 0.8212\n","\n","Epoch 69\n","train Loss: 0.0203 Acc: 0.8504\n","valid Loss: 0.0272 Acc: 0.8268\n","\n","Epoch 70\n","train Loss: 0.0147 Acc: 0.9017\n","valid Loss: 0.0263 Acc: 0.8436\n","\n","Epoch 71\n","train Loss: 0.0167 Acc: 0.9038\n","valid Loss: 0.0264 Acc: 0.8380\n","\n","Epoch 72\n","train Loss: 0.0176 Acc: 0.8932\n","valid Loss: 0.0265 Acc: 0.8268\n","\n","Epoch 73\n","train Loss: 0.0184 Acc: 0.8761\n","valid Loss: 0.0257 Acc: 0.8212\n","\n","Epoch 74\n","train Loss: 0.0167 Acc: 0.8846\n","valid Loss: 0.0268 Acc: 0.8380\n","\n","Epoch 75\n","train Loss: 0.0183 Acc: 0.8675\n","valid Loss: 0.0280 Acc: 0.8212\n","\n","Epoch 76\n","train Loss: 0.0149 Acc: 0.9081\n","valid Loss: 0.0264 Acc: 0.8268\n","\n","Epoch 77\n","train Loss: 0.0154 Acc: 0.8846\n","valid Loss: 0.0294 Acc: 0.8268\n","\n","Epoch 78\n","train Loss: 0.0170 Acc: 0.8932\n","valid Loss: 0.0273 Acc: 0.8156\n","\n","Epoch 79\n","train Loss: 0.0165 Acc: 0.9124\n","valid Loss: 0.0290 Acc: 0.8324\n","\n","Epoch 80\n","train Loss: 0.0147 Acc: 0.9017\n","valid Loss: 0.0251 Acc: 0.8212\n","\n","Epoch 81\n","train Loss: 0.0135 Acc: 0.9060\n","valid Loss: 0.0252 Acc: 0.8380\n","\n","Epoch 82\n","train Loss: 0.0165 Acc: 0.8889\n","valid Loss: 0.0275 Acc: 0.8436\n","\n","Epoch 83\n","train Loss: 0.0160 Acc: 0.8974\n","valid Loss: 0.0310 Acc: 0.8268\n","\n","Epoch 84\n","train Loss: 0.0150 Acc: 0.8932\n","valid Loss: 0.0262 Acc: 0.8268\n","\n","Epoch 85\n","train Loss: 0.0145 Acc: 0.9060\n","valid Loss: 0.0297 Acc: 0.8268\n","\n","Epoch 86\n","train Loss: 0.0161 Acc: 0.8868\n","valid Loss: 0.0276 Acc: 0.8324\n","\n","Epoch 87\n","train Loss: 0.0150 Acc: 0.9038\n","valid Loss: 0.0276 Acc: 0.8268\n","\n","Epoch 88\n","train Loss: 0.0157 Acc: 0.9038\n","valid Loss: 0.0292 Acc: 0.8324\n","\n","Epoch 89\n","train Loss: 0.0182 Acc: 0.8953\n","valid Loss: 0.0273 Acc: 0.8268\n","\n","Epoch 90\n","train Loss: 0.0161 Acc: 0.8932\n","valid Loss: 0.0274 Acc: 0.8436\n","\n","Epoch 91\n","train Loss: 0.0159 Acc: 0.8996\n","valid Loss: 0.0270 Acc: 0.8324\n","\n","Epoch 92\n","train Loss: 0.0134 Acc: 0.9060\n","valid Loss: 0.0278 Acc: 0.8045\n","\n","Epoch 93\n","train Loss: 0.0119 Acc: 0.9252\n","valid Loss: 0.0272 Acc: 0.8268\n","\n","Epoch 94\n","train Loss: 0.0163 Acc: 0.8910\n","valid Loss: 0.0300 Acc: 0.8268\n","\n","Epoch 95\n","train Loss: 0.0123 Acc: 0.9359\n","valid Loss: 0.0268 Acc: 0.8324\n","\n","Epoch 96\n","train Loss: 0.0127 Acc: 0.9188\n","valid Loss: 0.0264 Acc: 0.8380\n","\n","Epoch 97\n","train Loss: 0.0113 Acc: 0.9274\n","valid Loss: 0.0268 Acc: 0.8268\n","\n","Epoch 98\n","train Loss: 0.0145 Acc: 0.8974\n","valid Loss: 0.0271 Acc: 0.8492\n","\n","Epoch 99\n","train Loss: 0.0151 Acc: 0.8953\n","valid Loss: 0.0320 Acc: 0.8380\n","\n","Epoch 100\n","train Loss: 0.0140 Acc: 0.9167\n","valid Loss: 0.0310 Acc: 0.8547\n","\n","Epoch 101\n","train Loss: 0.0156 Acc: 0.8889\n","valid Loss: 0.0333 Acc: 0.8603\n","\n","Epoch 102\n","train Loss: 0.0120 Acc: 0.9167\n","valid Loss: 0.0286 Acc: 0.8324\n","\n","Epoch 103\n","train Loss: 0.0146 Acc: 0.9060\n","valid Loss: 0.0286 Acc: 0.8324\n","\n","Epoch 104\n","train Loss: 0.0128 Acc: 0.9124\n","valid Loss: 0.0281 Acc: 0.8212\n","\n","Epoch 105\n","train Loss: 0.0125 Acc: 0.9124\n","valid Loss: 0.0309 Acc: 0.8324\n","\n","Epoch 106\n","train Loss: 0.0149 Acc: 0.8953\n","valid Loss: 0.0270 Acc: 0.8547\n","\n","Epoch 107\n","train Loss: 0.0158 Acc: 0.9124\n","valid Loss: 0.0290 Acc: 0.8603\n","\n","Epoch 108\n","train Loss: 0.0134 Acc: 0.9188\n","valid Loss: 0.0288 Acc: 0.8603\n","\n","Epoch 109\n","train Loss: 0.0141 Acc: 0.9060\n","valid Loss: 0.0354 Acc: 0.8547\n","\n","Epoch 110\n","train Loss: 0.0130 Acc: 0.9124\n","valid Loss: 0.0284 Acc: 0.8436\n","\n","Epoch 111\n","train Loss: 0.0117 Acc: 0.9274\n","valid Loss: 0.0289 Acc: 0.8547\n","\n","Epoch 112\n","train Loss: 0.0114 Acc: 0.9209\n","valid Loss: 0.0321 Acc: 0.8547\n","\n","Epoch 113\n","train Loss: 0.0134 Acc: 0.9231\n","valid Loss: 0.0356 Acc: 0.8603\n","\n","Epoch 114\n","train Loss: 0.0131 Acc: 0.9145\n","valid Loss: 0.0271 Acc: 0.8436\n","\n","Epoch 115\n","train Loss: 0.0117 Acc: 0.9252\n","valid Loss: 0.0286 Acc: 0.8547\n","\n","Epoch 116\n","train Loss: 0.0140 Acc: 0.9188\n","valid Loss: 0.0292 Acc: 0.8603\n","\n","Epoch 117\n","train Loss: 0.0119 Acc: 0.9209\n","valid Loss: 0.0281 Acc: 0.8603\n","\n","Epoch 118\n","train Loss: 0.0132 Acc: 0.9167\n","valid Loss: 0.0290 Acc: 0.8492\n","\n","Epoch 119\n","train Loss: 0.0132 Acc: 0.9081\n","valid Loss: 0.0307 Acc: 0.8436\n","\n","Epoch 120\n","train Loss: 0.0118 Acc: 0.9338\n","valid Loss: 0.0318 Acc: 0.8436\n","\n","Epoch 121\n","train Loss: 0.0124 Acc: 0.9145\n","valid Loss: 0.0307 Acc: 0.8436\n","\n","Epoch 122\n","train Loss: 0.0117 Acc: 0.9188\n","valid Loss: 0.0374 Acc: 0.8492\n","\n","Epoch 123\n","train Loss: 0.0098 Acc: 0.9402\n","valid Loss: 0.0354 Acc: 0.8492\n","\n","Epoch 124\n","train Loss: 0.0133 Acc: 0.9017\n","valid Loss: 0.0326 Acc: 0.8268\n","\n","Epoch 125\n","train Loss: 0.0162 Acc: 0.9252\n","valid Loss: 0.0343 Acc: 0.8268\n","\n","Epoch 126\n","train Loss: 0.0111 Acc: 0.9188\n","valid Loss: 0.0317 Acc: 0.8436\n","\n","Epoch 127\n","train Loss: 0.0113 Acc: 0.9295\n","valid Loss: 0.0316 Acc: 0.8492\n","\n","Epoch 128\n","train Loss: 0.0113 Acc: 0.9252\n","valid Loss: 0.0297 Acc: 0.8436\n","\n","Epoch 129\n","train Loss: 0.0107 Acc: 0.9274\n","valid Loss: 0.0307 Acc: 0.8380\n","\n","Epoch 130\n","train Loss: 0.0104 Acc: 0.9402\n","valid Loss: 0.0332 Acc: 0.8324\n","\n","Epoch 131\n","train Loss: 0.0111 Acc: 0.9316\n","valid Loss: 0.0371 Acc: 0.8436\n","\n","Epoch 132\n","train Loss: 0.0114 Acc: 0.9209\n","valid Loss: 0.0394 Acc: 0.8324\n","\n","Epoch 133\n","train Loss: 0.0119 Acc: 0.9231\n","valid Loss: 0.0320 Acc: 0.8268\n","\n","Epoch 134\n","train Loss: 0.0110 Acc: 0.9167\n","valid Loss: 0.0315 Acc: 0.8268\n","\n","Epoch 135\n","train Loss: 0.0111 Acc: 0.9252\n","valid Loss: 0.0324 Acc: 0.8436\n","\n","Epoch 136\n","train Loss: 0.0114 Acc: 0.9188\n","valid Loss: 0.0357 Acc: 0.8492\n","\n","Epoch 137\n","train Loss: 0.0146 Acc: 0.9103\n","valid Loss: 0.0335 Acc: 0.8380\n","\n","Epoch 138\n","train Loss: 0.0098 Acc: 0.9359\n","valid Loss: 0.0400 Acc: 0.8268\n","\n","Epoch 139\n","train Loss: 0.0107 Acc: 0.9338\n","valid Loss: 0.0340 Acc: 0.8380\n","\n","Epoch 140\n","train Loss: 0.0090 Acc: 0.9423\n","valid Loss: 0.0360 Acc: 0.8268\n","\n","Epoch 141\n","train Loss: 0.0093 Acc: 0.9359\n","valid Loss: 0.0316 Acc: 0.8380\n","\n","Epoch 142\n","train Loss: 0.0110 Acc: 0.9295\n","valid Loss: 0.0325 Acc: 0.8436\n","\n","Epoch 143\n","train Loss: 0.0105 Acc: 0.9380\n","valid Loss: 0.0345 Acc: 0.8436\n","\n","Epoch 144\n","train Loss: 0.0135 Acc: 0.9295\n","valid Loss: 0.0348 Acc: 0.8380\n","\n","Epoch 145\n","train Loss: 0.0112 Acc: 0.9380\n","valid Loss: 0.0337 Acc: 0.8492\n","\n","Epoch 146\n","train Loss: 0.0110 Acc: 0.9316\n","valid Loss: 0.0344 Acc: 0.8603\n","\n","Epoch 147\n","train Loss: 0.0102 Acc: 0.9466\n","valid Loss: 0.0410 Acc: 0.8603\n","\n","Epoch 148\n","train Loss: 0.0134 Acc: 0.9295\n","valid Loss: 0.0320 Acc: 0.8436\n","\n","Epoch 149\n","train Loss: 0.0118 Acc: 0.9252\n","valid Loss: 0.0331 Acc: 0.8547\n","\n","Epoch 150\n","train Loss: 0.0107 Acc: 0.9274\n","valid Loss: 0.0333 Acc: 0.8547\n","\n","Epoch 151\n","train Loss: 0.0099 Acc: 0.9380\n","valid Loss: 0.0344 Acc: 0.8324\n","\n","Epoch 152\n","train Loss: 0.0101 Acc: 0.9423\n","valid Loss: 0.0333 Acc: 0.8436\n","\n","Epoch 153\n","train Loss: 0.0100 Acc: 0.9402\n","valid Loss: 0.0345 Acc: 0.8436\n","\n","Epoch 154\n","train Loss: 0.0122 Acc: 0.9316\n","valid Loss: 0.0411 Acc: 0.8436\n","\n","Epoch 155\n","train Loss: 0.0115 Acc: 0.9316\n","valid Loss: 0.0385 Acc: 0.8324\n","\n","Epoch 156\n","train Loss: 0.0107 Acc: 0.9338\n","valid Loss: 0.0356 Acc: 0.8324\n","\n","Epoch 157\n","train Loss: 0.0110 Acc: 0.9338\n","valid Loss: 0.0378 Acc: 0.8492\n","\n","Epoch 158\n","train Loss: 0.0101 Acc: 0.9316\n","valid Loss: 0.0354 Acc: 0.8324\n","\n","Epoch 159\n","train Loss: 0.0094 Acc: 0.9402\n","valid Loss: 0.0430 Acc: 0.8436\n","\n","Epoch 160\n","train Loss: 0.0089 Acc: 0.9615\n","valid Loss: 0.0357 Acc: 0.8268\n","\n","Epoch 161\n","train Loss: 0.0097 Acc: 0.9466\n","valid Loss: 0.0438 Acc: 0.8268\n","\n","Epoch 162\n","train Loss: 0.0097 Acc: 0.9338\n","valid Loss: 0.0343 Acc: 0.8380\n","\n","Epoch 163\n","train Loss: 0.0109 Acc: 0.9316\n","valid Loss: 0.0362 Acc: 0.8436\n","\n","Epoch 164\n","train Loss: 0.0101 Acc: 0.9466\n","valid Loss: 0.0363 Acc: 0.8492\n","\n","Epoch 165\n","train Loss: 0.0120 Acc: 0.9188\n","valid Loss: 0.0396 Acc: 0.8324\n","\n","Epoch 166\n","train Loss: 0.0104 Acc: 0.9338\n","valid Loss: 0.0379 Acc: 0.8380\n","\n","Epoch 167\n","train Loss: 0.0102 Acc: 0.9402\n","valid Loss: 0.0343 Acc: 0.8268\n","\n","Epoch 168\n","train Loss: 0.0090 Acc: 0.9316\n","valid Loss: 0.0345 Acc: 0.8380\n","\n","Epoch 169\n","train Loss: 0.0106 Acc: 0.9444\n","valid Loss: 0.0373 Acc: 0.8324\n","\n","Epoch 170\n","train Loss: 0.0082 Acc: 0.9530\n","valid Loss: 0.0383 Acc: 0.8324\n","\n","Epoch 171\n","train Loss: 0.0111 Acc: 0.9402\n","valid Loss: 0.0372 Acc: 0.8268\n","\n","Epoch 172\n","train Loss: 0.0097 Acc: 0.9359\n","valid Loss: 0.0362 Acc: 0.8380\n","\n","Epoch 173\n","train Loss: 0.0072 Acc: 0.9594\n","valid Loss: 0.0357 Acc: 0.8268\n","\n","Epoch 174\n","train Loss: 0.0100 Acc: 0.9423\n","valid Loss: 0.0351 Acc: 0.8380\n","\n","Epoch 175\n","train Loss: 0.0095 Acc: 0.9359\n","valid Loss: 0.0438 Acc: 0.8436\n","\n","Epoch 176\n","train Loss: 0.0104 Acc: 0.9444\n","valid Loss: 0.0433 Acc: 0.8324\n","\n","Epoch 177\n","train Loss: 0.0097 Acc: 0.9444\n","valid Loss: 0.0430 Acc: 0.8492\n","\n","Epoch 178\n","train Loss: 0.0094 Acc: 0.9359\n","valid Loss: 0.0372 Acc: 0.8436\n","\n","Epoch 179\n","train Loss: 0.0092 Acc: 0.9338\n","valid Loss: 0.0364 Acc: 0.8212\n","\n","Epoch 180\n","train Loss: 0.0122 Acc: 0.9423\n","valid Loss: 0.0381 Acc: 0.8324\n","\n","Epoch 181\n","train Loss: 0.0079 Acc: 0.9551\n","valid Loss: 0.0434 Acc: 0.8324\n","\n","Epoch 182\n","train Loss: 0.0083 Acc: 0.9487\n","valid Loss: 0.0374 Acc: 0.8380\n","\n","Epoch 183\n","train Loss: 0.0101 Acc: 0.9487\n","valid Loss: 0.0382 Acc: 0.8268\n","\n","Epoch 184\n","train Loss: 0.0084 Acc: 0.9487\n","valid Loss: 0.0348 Acc: 0.8436\n","\n","Epoch 185\n","train Loss: 0.0100 Acc: 0.9295\n","valid Loss: 0.0353 Acc: 0.8436\n","\n","Epoch 186\n","train Loss: 0.0119 Acc: 0.9316\n","valid Loss: 0.0375 Acc: 0.8547\n","\n","Epoch 187\n","train Loss: 0.0100 Acc: 0.9444\n","valid Loss: 0.0327 Acc: 0.8268\n","\n","Epoch 188\n","train Loss: 0.0070 Acc: 0.9722\n","valid Loss: 0.0382 Acc: 0.8268\n","\n","Epoch 189\n","train Loss: 0.0097 Acc: 0.9274\n","valid Loss: 0.0345 Acc: 0.8603\n","\n","Epoch 190\n","train Loss: 0.0084 Acc: 0.9380\n","valid Loss: 0.0346 Acc: 0.8324\n","\n","Epoch 191\n","train Loss: 0.0079 Acc: 0.9423\n","valid Loss: 0.0370 Acc: 0.8547\n","\n","Epoch 192\n","train Loss: 0.0063 Acc: 0.9615\n","valid Loss: 0.0351 Acc: 0.8324\n","\n","Epoch 193\n","train Loss: 0.0089 Acc: 0.9380\n","valid Loss: 0.0348 Acc: 0.8436\n","\n","Epoch 194\n","train Loss: 0.0089 Acc: 0.9380\n","valid Loss: 0.0375 Acc: 0.8436\n","\n","Epoch 195\n","train Loss: 0.0102 Acc: 0.9509\n","valid Loss: 0.0373 Acc: 0.8324\n","\n","Epoch 196\n","train Loss: 0.0084 Acc: 0.9444\n","valid Loss: 0.0380 Acc: 0.8380\n","\n","Epoch 197\n","train Loss: 0.0089 Acc: 0.9359\n","valid Loss: 0.0436 Acc: 0.8268\n","\n","Epoch 198\n","train Loss: 0.0096 Acc: 0.9359\n","valid Loss: 0.0394 Acc: 0.8268\n","\n","Epoch 199\n","train Loss: 0.0062 Acc: 0.9615\n","valid Loss: 0.0431 Acc: 0.8212\n","\n","Training complete in 51m 14s\n","Best val Acc: 0.972222\n","test Loss: 0.0141 Acc: 0.9213\n"]}],"source":["epochs = 200\n","# model = torch.load(r'E:\\Ud project\\model1.pkl')\n","model = train_model(net, criterion, optimizer, epochs)\n","# model = train_model(model, criterion, optimizer, epochs)\n","test_model(model,criterion)\n","torch.save(model, r'/content/drive/MyDrive/Datasets/61/200_6_23.pkl')\n","torch.save(model, r'/content/drive/MyDrive/Datasets/61/200_7_23.model')"]}]}